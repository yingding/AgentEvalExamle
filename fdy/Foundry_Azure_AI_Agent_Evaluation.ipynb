{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54d68331",
   "metadata": {},
   "source": [
    "# Evaluating an Azure AI Agent with Azure AI Evaluation SDK\n",
    "\n",
    "GBB learning sessione example to demonstrate how to evaluate an **Azure AI Agent** using three quality metrics provided by the Azure AI Evaluation SDK (preview):\n",
    "1. **Intent Resolution** – Did the agent understand and address the user’s request?\n",
    "2. **Tool Call Accuracy** – Did the agent choose and invoke the correct tool(s) with the right parameters?\n",
    "3. **Task Adherence** – Did the agent follow its instructions and complete the assigned task?\n",
    "\n",
    "Created a mock `fetch_weather` tool, simulate an agent response in various scenarios (correct, incorrect, unspecified / right tool chosen, wrong tool chosen) and evaluate with the SDK."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c3cb89",
   "metadata": {},
   "source": [
    "## Setup Azure credentials and project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25458309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and authentication OK\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "from utils.fdyauth import AuthHelper\n",
    "settings = AuthHelper.load_settings()\n",
    "credential = AuthHelper.test_credential()\n",
    "\n",
    "if credential:\n",
    "    print('Environment and authentication OK')\n",
    "else:\n",
    "    print(\"please login first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623e457e",
   "metadata": {},
   "source": [
    "## Create a sample agent and `fetch_weather` tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "478375a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project client api version: 2025-05-15-preview\n",
      "Created agent 'Weather Assistant' with 2 tools\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.agents.models import (\n",
    "    FunctionTool,\n",
    "    ToolSet\n",
    ")\n",
    "import json\n",
    "# from typing import Callable, Any, Set\n",
    "\n",
    "def fetch_weather(location: str) -> str:\n",
    "    \"\"\"Mock weather service\"\"\"\n",
    "    mock_weather_data = {\n",
    "        'Seattle': 'Sunny, 25°C',\n",
    "        'London': 'Cloudy, 18°C',\n",
    "        'Tokyo': 'Rainy, 22°C'\n",
    "    }\n",
    "    return json.dumps({'weather': mock_weather_data.get(location, 'N/A')})\n",
    "\n",
    "def fetch_funfact(location: str) -> str:\n",
    "    \"\"\"Fun fact about a location\"\"\"\n",
    "    mock_weather_data = {\n",
    "        'Seattle': 'There are whales',\n",
    "        'London': 'Is the capital of England',\n",
    "        'Tokyo': 'Has the highest population density in the world'\n",
    "    }\n",
    "    return json.dumps({'weather': mock_weather_data.get(location, 'N/A')})\n",
    "\n",
    "# Initialize project client with proper authentication\n",
    "project_client = AIProjectClient(\n",
    "    credential=credential,  # Use the credential from earlier setup\n",
    "    endpoint=settings.project_endpoint\n",
    ")\n",
    "print(f\"project client api version: {project_client._config.api_version}\")\n",
    "    \n",
    "# Register functions as tools\n",
    "# custom_fns: Set[Callable[..., Any]] = {fetch_weather, fetch_funfact}\n",
    "functions = FunctionTool({fetch_weather, fetch_funfact})\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "    \n",
    "# Create agent with proper error handling\n",
    "AGENT_NAME = settings.agent_name\n",
    "AGENT_INSTRUCTIONS = \"\"\"You are a helpful weather assistant. When asked about the weather in a location:\n",
    "            1. Use fetch_weather to get current conditions\n",
    "            2. Provide clear, concise responses\n",
    "            3. Stay focused on weather information\n",
    "            Always use tools when available and verify data before responding.\"\"\"\n",
    "\n",
    "found_agent = None\n",
    "all_agents_list = project_client.agents.list_agents()\n",
    "for a in all_agents_list:\n",
    "    if a.name == AGENT_NAME:\n",
    "        found_agent = a\n",
    "        break\n",
    "\n",
    "project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4)\n",
    "if found_agent:\n",
    "    agent = project_client.agents.update_agent(\n",
    "        agent_id=found_agent.id,\n",
    "        model=settings.model_deployment_name,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4) \n",
    "    print(f\"reusing agent > {agent.name} (id: {agent.id})\")\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=settings.model_deployment_name,\n",
    "        name=AGENT_NAME,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    print(f\"Created agent '{AGENT_NAME}' with {len(functions._functions)} tools\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f10b321",
   "metadata": {},
   "source": [
    "## Simulate a user query and agent responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72704a69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What's the weather in Seattle?\n",
      "Agent (correct): The current weather in Seattle is Sunny, 25°C.\n",
      "Agent (incorrect): The weather in Seattle is Rainy, 15°C. In London, it's Sunny, 28°C.\n",
      "\n",
      "User: How much does it rain in Spain?\n",
      "Agent without information, providing irrelevant information\n"
     ]
    }
   ],
   "source": [
    "user_question = \"What's the weather in Seattle?\"\n",
    "user_question_unspecific = \"How much does it rain in Spain?\"\n",
    "\n",
    "# Correct tool usage\n",
    "import json\n",
    "weather_seattle = json.loads(fetch_weather('Seattle'))['weather']\n",
    "weather_london = json.loads(fetch_weather('London'))['weather']\n",
    "agent_response_correct = (\n",
    "    f'The current weather in Seattle is {weather_seattle}.'\n",
    ")\n",
    "\n",
    "# Incorrect tool usage (wrong location)\n",
    "agent_response_incorrect = (\n",
    "    'The weather in Seattle is Rainy, 15°C. In London, it\\'s Sunny, 28°C.'\n",
    ")\n",
    "\n",
    "print('User:', user_question)\n",
    "print('Agent (correct):', agent_response_correct)\n",
    "print('Agent (incorrect):', agent_response_incorrect)\n",
    "\n",
    "print('\\nUser:', user_question_unspecific)\n",
    "print('Agent without information, providing irrelevant information')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f10e8",
   "metadata": {},
   "source": [
    "## Initialize evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9170512f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class ToolCallAccuracyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class TaskAdherenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluators setup\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AzureOpenAIModelConfiguration\n",
    "from azure.ai.evaluation import (\n",
    "    IntentResolutionEvaluator,\n",
    "    ToolCallAccuracyEvaluator,\n",
    "    TaskAdherenceEvaluator,\n",
    ")\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=settings.azure_openai_endpoint,\n",
    "    api_key=settings.azure_openai_api_key,\n",
    "    api_version=settings.azure_openai_api_version,\n",
    "    azure_deployment=settings.model_deployment_name,\n",
    ")\n",
    "\n",
    "intent_eval = IntentResolutionEvaluator(model_config=model_config)\n",
    "tool_eval = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "task_eval = TaskAdherenceEvaluator(model_config=model_config)\n",
    "print('Evaluators setup')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecce7fc",
   "metadata": {},
   "source": [
    "### Intent Resolution\n",
    "\n",
    "Measures how well the agent identifies the user’s request, including how well it scopes the user’s intent, asks clarifying questions, and reminds end users of its scope of capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "698bd77b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\n",
      "{'additional_details': {'actual_user_intent': 'request for current weather in Seattle',\n",
      "                        'agent_perceived_intent': 'request for current weather in Seattle',\n",
      "                        'conversation_has_intent': True,\n",
      "                        'correct_intent_detected': True,\n",
      "                        'intent_resolved': True},\n",
      " 'intent_resolution': 5.0,\n",
      " 'intent_resolution_reason': \"The response directly answers the user's query by providing the current weather \"\n",
      "                             \"condition and temperature in Seattle, fully addressing the user's request for weather \"\n",
      "                             'information.',\n",
      " 'intent_resolution_result': 'pass',\n",
      " 'intent_resolution_threshold': 3}\n",
      "\n",
      "Incorrect:\n",
      "{'additional_details': {'actual_user_intent': 'know the weather in Seattle',\n",
      "                        'agent_perceived_intent': 'provide current weather information for Seattle',\n",
      "                        'conversation_has_intent': True,\n",
      "                        'correct_intent_detected': True,\n",
      "                        'intent_resolved': True},\n",
      " 'intent_resolution': 5.0,\n",
      " 'intent_resolution_reason': \"The response correctly identifies the user's intent to know the weather in Seattle and \"\n",
      "                             'provides the requested information accurately. However, it also includes unrelated '\n",
      "                             \"weather information about London, which is not relevant to the user's query. Despite \"\n",
      "                             'this minor extraneous detail, the main intent is fully addressed with accurate and '\n",
      "                             \"relevant information about Seattle's weather.\",\n",
      " 'intent_resolution_result': 'pass',\n",
      " 'intent_resolution_threshold': 3}\n",
      "\n",
      "Unspecific:\n",
      "{'additional_details': {'actual_user_intent': 'know how much it rains in Spain',\n",
      "                        'agent_perceived_intent': 'provide weather information for cities',\n",
      "                        'conversation_has_intent': True,\n",
      "                        'correct_intent_detected': False,\n",
      "                        'intent_resolved': False},\n",
      " 'intent_resolution': 1.0,\n",
      " 'intent_resolution_reason': 'The response provides weather information for Seattle and London, which is unrelated to '\n",
      "                             \"the user's query about rainfall in Spain. It does not address the user's intent to learn \"\n",
      "                             'about the amount of rain in Spain at all.',\n",
      " 'intent_resolution_result': 'fail',\n",
      " 'intent_resolution_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "res_intent_correct = intent_eval(query=user_question, response=agent_response_correct)\n",
    "res_intent_incorrect = intent_eval(query=user_question, response=agent_response_incorrect)\n",
    "res_intent_unspecific = intent_eval(query=user_question_unspecific, response=agent_response_incorrect)\n",
    "print('Correct:')\n",
    "pprint(res_intent_correct, width=120, compact=True)\n",
    "print('\\nIncorrect:')\n",
    "pprint(res_intent_incorrect, width=120, compact=True)\n",
    "print('\\nUnspecific:')\n",
    "pprint(res_intent_unspecific, width=120, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea6942d",
   "metadata": {},
   "source": [
    "### Tool Call Accuracy\n",
    "\n",
    "Evaluates the agent’s ability to select the appropriate tools, and process correct parameters from previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95491b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\n",
      "{'per_tool_call_details': [],\n",
      " 'tool_call_accuracy': 'not applicable',\n",
      " 'tool_call_accuracy_reason': 'Tool call accuracy evaluation is not yet supported for the invoked tools.',\n",
      " 'tool_call_accuracy_result': 'not applicable',\n",
      " 'tool_call_accuracy_threshold': 0.8}\n",
      "\n",
      "Incorrect:\n",
      "{'per_tool_call_details': [],\n",
      " 'tool_call_accuracy': 'not applicable',\n",
      " 'tool_call_accuracy_reason': 'Tool call accuracy evaluation is not yet supported for the invoked tools.',\n",
      " 'tool_call_accuracy_result': 'not applicable',\n",
      " 'tool_call_accuracy_threshold': 0.8}\n"
     ]
    }
   ],
   "source": [
    "tool_definitions = [\n",
    "    {\n",
    "        'name': 'fetch_weather',\n",
    "        'description': 'Fetches weather information for a location.',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'location': {'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        'name': 'fetch_funfact',\n",
    "        'description': 'Fetches a fun fact about a location.',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'properties': {\n",
    "                'location': {'type': 'string'}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "tool_calls_correct = [\n",
    "    {'type': 'tool_call', 'tool_call_id': 'call_1', 'name': 'fetch_weather', 'arguments': {'location': 'Seattle'}},\n",
    "]\n",
    "tool_calls_incorrect = [\n",
    "    {'type': 'tool_call', 'tool_call_id': 'bad_call', 'name': 'fetch_funfact', 'arguments': {'location': 'Tokyo'}},\n",
    "]\n",
    "\n",
    "res_tool_correct = tool_eval(query=user_question, tool_calls=tool_calls_correct, tool_definitions=tool_definitions)\n",
    "res_tool_incorrect = tool_eval(query=user_question, tool_calls=tool_calls_incorrect, tool_definitions=tool_definitions)\n",
    "\n",
    "\n",
    "print('Correct:')\n",
    "pprint(res_tool_correct, width=120, compact=True)\n",
    "print('\\nIncorrect:')\n",
    "pprint(res_tool_incorrect, width=120, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c40c59",
   "metadata": {},
   "source": [
    "### Task Adherence\n",
    "\n",
    " Measures how well the agent’s final response adheres to its assigned tasks, according to its system message and prior steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "762f19c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct:\n",
      "{'task_adherence': 5.0,\n",
      " 'task_adherence_reason': \"The response is clear, accurate, and directly answers the query about Seattle's weather, \"\n",
      "                          'fulfilling the task completely without any gaps or errors.',\n",
      " 'task_adherence_result': 'pass',\n",
      " 'task_adherence_threshold': 3}\n",
      "\n",
      "Incorrect:\n",
      "{'task_adherence': 4.0,\n",
      " 'task_adherence_reason': \"The response answers the query about Seattle's weather but includes irrelevant information \"\n",
      "                          'about London, which is unnecessary and detracts from clarity, making it mostly adherent but '\n",
      "                          'not perfect.',\n",
      " 'task_adherence_result': 'pass',\n",
      " 'task_adherence_threshold': 3}\n",
      "\n",
      "Unspecific:\n",
      "{'task_adherence': 1.0,\n",
      " 'task_adherence_reason': 'The response is completely off-topic and does not answer the question about rainfall in '\n",
      "                          'Spain, thus it is fully inadherent to the task.',\n",
      " 'task_adherence_result': 'fail',\n",
      " 'task_adherence_threshold': 3}\n"
     ]
    }
   ],
   "source": [
    "res_task_correct = task_eval(query=user_question, response=agent_response_correct, tool_calls=tool_calls_correct)\n",
    "res_task_incorrect = task_eval(query=user_question, response=agent_response_incorrect, tool_calls=tool_calls_incorrect)\n",
    "res_task_unspecific = task_eval(query=user_question_unspecific, response=agent_response_incorrect, tool_calls=tool_calls_incorrect)\n",
    "print('Correct:')\n",
    "pprint(res_task_correct, width=120, compact=True)\n",
    "print('\\nIncorrect:')\n",
    "pprint(res_task_incorrect, width=120, compact=True)\n",
    "print('\\nUnspecific:')\n",
    "pprint(res_task_unspecific, width=120, compact=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f8324",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- **Intent Resolution** confirmed the agent understood the request in both scenarios.\n",
    "- **Tool Call Accuracy** detected the incorrect tool usage in the flawed scenario.\n",
    "- **Task Adherence** showed the agent followed instructions even when factual output was wrong.\n",
    "\n",
    "Use these insights to improve your agent’s tool selection logic and answer verification. For production, combine these metrics with others (e.g., factuality, safety) for a complete quality picture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azfdyagents3.12pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
