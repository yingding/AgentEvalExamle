{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate AI agents (Azure AI Agent Service) in Azure AI Foundry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "\n",
    "This sample demonstrates how to evaluate an AI agent (Azure AI Agent Service) on these important aspects of your agentic workflow:\n",
    "\n",
    "- Intent Resolution: Measures how well the agent identifies the user’s request, including how well it scopes the user’s intent, asks clarifying questions, and reminds end users of its scope of capabilities.\n",
    "- Tool Call Accuracy: Evaluates the agent's ability to select the appropriate tools, and process correct parameters from previous steps.\n",
    "- Task Adherence: Measures how well the agent’s response adheres to its assigned tasks, according to its system message and prior steps.\n",
    "\n",
    "For AI agents outside of Azure AI Agent Service, you can still provide th agent data in the two formats (either simple data or agent messages) specified in the individual evaluator samples:\n",
    "- [Intent resolution](https://aka.ms/intentresolution-sample)\n",
    "- [Tool call accuracy](https://aka.ms/toolcallaccuracy-sample)\n",
    "- [Task adherence](https://aka.ms/taskadherence-sample)\n",
    "- [Response Completeness](https://aka.ms/rescompleteness-sample)\n",
    "\n",
    "\n",
    "\n",
    "## Time \n",
    "\n",
    "You should expect to spend about 20 minutes running this notebook. \n",
    "\n",
    "## Before you begin\n",
    "Creating an agent using Azure AI agent service requires an Azure AI Foundry project and a deployed, supported model. See more details in [Create a new agent](https://learn.microsoft.com/azure/ai-services/agents/quickstart?pivots=ai-foundry-portal).\n",
    "\n",
    "For quality evaluation, you need to deploy a `gpt` model supporting JSON mode. We recommend a model `gpt-4o` or `gpt-4o-mini` for their strong reasoning capabilities.    \n",
    "\n",
    "Important: Make sure to authenticate to Azure using `az login` in your terminal before running this notebook.\n",
    "\n",
    "### Prerequisite\n",
    "\n",
    "Before running the sample:\n",
    "```bash\n",
    "pip install azure-ai-projects azure-identity azure-ai-evaluation\n",
    "```\n",
    "Set these environment variables with your own values:\n",
    "1) **PROJECT_CONNECTION_STRING** - The project connection string, as found in the overview page of your Azure AI Foundry project.\n",
    "2) **MODEL_DEPLOYMENT_NAME** - The deployment name of the model for AI-assisted evaluators, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project.\n",
    "3) **AZURE_OPENAI_ENDPOINT** - Azure Open AI Endpoint to be used for evaluation.\n",
    "4) **AZURE_OPENAI_API_KEY** - Azure Open AI Key to be used for evaluation.\n",
    "5) **AZURE_OPENAI_API_VERSION** - Azure Open AI Api version to be used for evaluation.\n",
    "6) **AZURE_SUBSCRIPTION_ID** - Azure Subscription Id of Azure AI Project\n",
    "7) **PROJECT_NAME** - Azure AI Project Name\n",
    "8) **RESOURCE_GROUP_NAME** - Azure AI Project Resource Group Name\n",
    "9) **AGENT_MODEL_DEPLOYMENT_NAME** - The deployment name of the model for your Azure AI agent, as found under the \"Name\" column in the \"Models + endpoints\" tab in your Azure AI Foundry project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Azure credentials and project \n",
    "1. use az cli to login to the tenant with your credential\n",
    "\n",
    "<!-- initializing Project Client -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment and authentication OK\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "from utils.fdyauth import AuthHelper\n",
    "settings = AuthHelper.load_settings()\n",
    "credential = AuthHelper.test_credential()\n",
    "\n",
    "if credential:\n",
    "    print('Environment and authentication OK')\n",
    "else:\n",
    "    print(\"please login first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project client api version: 2025-05-15-preview\n",
      "azure-ai-agents version: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import azure.ai.agents as agentslib\n",
    "from azure.ai.projects import AIProjectClient\n",
    "from azure.ai.projects.models import (\n",
    "    AgentEvaluationRequest,\n",
    "    InputDataset,\n",
    "    EvaluatorIds,\n",
    "    EvaluatorConfiguration,\n",
    "    AgentEvaluationSamplingConfiguration,\n",
    "    AgentEvaluationRedactionConfiguration,\n",
    "    Evaluation,\n",
    "    DatasetVersion,\n",
    "    FileDatasetVersion,\n",
    ")\n",
    "from azure.ai.agents.models import (\n",
    "    FunctionTool,\n",
    "    ToolSet,\n",
    "    MessageRole,\n",
    ")\n",
    "\n",
    "# Import your custom functions to be used as Tools for the Agent\n",
    "from utils.user_functions import user_functions\n",
    "\n",
    "# Initialize project client with proper authentication\n",
    "project_client = AIProjectClient(\n",
    "    credential=credential,  # Use the credential from earlier setup\n",
    "    endpoint=settings.project_endpoint\n",
    ")\n",
    "print(f\"project client api version: {project_client._config.api_version}\")\n",
    "print(f\"azure-ai-agents version: {agentslib.__version__}\")\n",
    "\n",
    "AGENT_NAME = \"Seattle Tourist Assistant\"\n",
    "AGENT_INSTRUCTIONS = \"\"\"You are a helpful tourist assistant\"\"\"\n",
    "\n",
    "# Add Tools to be used by Agent\n",
    "functions = FunctionTool(user_functions)\n",
    "\n",
    "toolset = ToolSet()\n",
    "toolset.add(functions)\n",
    "\n",
    "# To enable tool calls executed automatically\n",
    "project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an AI agent (Azure AI Agent Service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reusing agent > Seattle Tourist Assistant (id: asst_MSuuqYfXRGp34r33IF6DO0D0)\n"
     ]
    }
   ],
   "source": [
    "found_agent = None\n",
    "all_agents_list = project_client.agents.list_agents()\n",
    "for a in all_agents_list:\n",
    "    if a.name == AGENT_NAME:\n",
    "        found_agent = a\n",
    "        break\n",
    "\n",
    "if found_agent:\n",
    "    agent = project_client.agents.update_agent(\n",
    "        agent_id=found_agent.id,\n",
    "        model=settings.model_deployment_name,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    project_client.agents.enable_auto_function_calls(tools=toolset, max_retry=4) \n",
    "    print(f\"reusing agent > {agent.name} (id: {agent.id})\")\n",
    "else:\n",
    "    agent = project_client.agents.create_agent(\n",
    "        model=settings.model_deployment_name,\n",
    "        name=AGENT_NAME,\n",
    "        instructions=AGENT_INSTRUCTIONS,\n",
    "        toolset=toolset,\n",
    "    )\n",
    "    print(f\"Created agent '{AGENT_NAME}' with {len(functions._functions)} tools\\nID: {agent.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created thread, ID: thread_N8cK5BNhIOXzJmm5N9Ol6FgT\n"
     ]
    }
   ],
   "source": [
    "thread = project_client.agents.threads.create()\n",
    "print(f\"Created thread, ID: {thread.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversation with Agent\n",
    "Use below cells to have conversation with the agent\n",
    "- `Create Message[1]`\n",
    "- `Execute[2]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Message[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created message, ID: msg_pPuYLfy6VYaOuNS5L9ysQn3V\n"
     ]
    }
   ],
   "source": [
    "# Create message to thread\n",
    "\n",
    "MESSAGE = \"Can you email me weather info for Seattle ?\"\n",
    "\n",
    "message = project_client.agents.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=MessageRole.USER,\n",
    "    content=MESSAGE,\n",
    ")\n",
    "print(f\"Created message, ID: {message.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run finished with status: RunStatus.COMPLETED\n",
      "Run ID: run_nptDN2Q3yToS9vT3dfPodM9q\n"
     ]
    }
   ],
   "source": [
    "run = project_client.agents.runs.create_and_process(thread_id=thread.id, agent_id=agent.id)\n",
    "\n",
    "print(f\"Run finished with status: {run.status}\")\n",
    "\n",
    "if run.status == \"failed\":\n",
    "    print(f\"Run failed: {run.last_error}\")\n",
    "\n",
    "print(f\"Run ID: {run.id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Role: MessageRole.USER\n",
      "Content: Can you email me weather info for Seattle ?\n",
      "----------------------------------------\n",
      "Role: MessageRole.AGENT\n",
      "Content: Could you please provide me with your email address so that I can send you the weather information for Seattle?\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for message in project_client.agents.messages.list(thread.id, order=\"asc\"):\n",
    "    print(f\"Role: {message.role}\")\n",
    "    print(f\"Content: {message.content[0].text.value}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation in the cloud\n",
    "\n",
    "Reference:\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/cloud-evaluation\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/cloud-evaluation#prerequisite-set-up-steps-for-azure-ai-foundry-projects\n",
    "\n",
    "For the Microsoft Entra ID, give MSI (Microsoft Identity) permissions for \"Storage Blob Data Owner\" through IAM to both\n",
    "* `User, group, or service principal` \"EntraID user\" and\n",
    "* `Managed Identity` by adding the Role to both `Azure AI Foundry Resource` and its `Azure AI Foundry Project`\n",
    "from the storage account IAM.\n",
    "* And make sure to choose \"Share to all project\" while adding the storage account connection to the Azure AI Foundry Project v2\n",
    "\n",
    "Adding additional `Azure AI Administrator Role` to the Microsoft EntraID User for the `Azure AI Foundry Resource`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data from agent response for evaluation\n",
    "\n",
    "Reference:\n",
    "* https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk#evaluate-azure-ai-agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'query': [{'role': 'system', 'content': 'You are a helpful tourist assistant'}, {'createdAt': '2025-06-27T14:25:53Z', 'role': 'user', 'content': [{'type': 'text', 'text': 'Can you email me weather info for Seattle ?'}]}], 'response': [{'createdAt': '2025-06-27T14:26:00Z', 'run_id': 'run_nptDN2Q3yToS9vT3dfPodM9q', 'role': 'assistant', 'content': [{'type': 'text', 'text': 'Could you please provide me with your email address so that I can send you the weather information for Seattle?'}]}], 'tool_definitions': [{'name': 'longest_word_in_sentences', 'type': 'function', 'description': 'Finds the longest word in each sentence.', 'parameters': {'type': 'object', 'properties': {'sentences': {'type': 'array', 'items': {'type': 'string'}, 'description': 'A list of sentences.'}}}}, {'name': 'toggle_flag', 'type': 'function', 'description': 'Toggles a boolean flag.', 'parameters': {'type': 'object', 'properties': {'flag': {'type': 'boolean', 'description': 'The flag to toggle.'}}}}, {'name': 'fetch_weather', 'type': 'function', 'description': 'Fetches the weather information for the specified location.', 'parameters': {'type': 'object', 'properties': {'location': {'type': 'string', 'description': 'The location to fetch weather for.'}}}}, {'name': 'calculate_sum', 'type': 'function', 'description': 'Calculates the sum of two integers.', 'parameters': {'type': 'object', 'properties': {'a': {'type': 'integer', 'description': 'First integer.'}, 'b': {'type': 'integer', 'description': 'Second integer.'}}}}, {'name': 'process_records', 'type': 'function', 'description': 'Process a list of records, where each record is a dictionary with string keys and integer values.', 'parameters': {'type': 'object', 'properties': {'records': {'type': 'array', 'items': {'type': 'object'}, 'description': 'A list containing dictionaries that map strings to integers.'}}}}, {'name': 'merge_dicts', 'type': 'function', 'description': 'Merges two dictionaries.', 'parameters': {'type': 'object', 'properties': {'dict1': {'type': 'object', 'description': 'First dictionary.'}, 'dict2': {'type': 'object', 'description': 'Second dictionary.'}}}}, {'name': 'opening_hours', 'type': 'function', 'description': 'Fetches the opening hours of a tourist destination in Seattle.', 'parameters': {'type': 'object', 'properties': {'tourist_destination': {'type': 'string', 'description': 'The tourist destination to fetch opening hours for.'}}}}, {'name': 'convert_temperature', 'type': 'function', 'description': 'Converts temperature from Celsius to Fahrenheit.', 'parameters': {'type': 'object', 'properties': {'celsius': {'type': 'number', 'description': 'Temperature in Celsius.'}}}}, {'name': 'send_email', 'type': 'function', 'description': 'Sends an email with the specified subject and body to the recipient.', 'parameters': {'type': 'object', 'properties': {'recipient': {'type': 'string', 'description': 'Email address of the recipient.'}, 'subject': {'type': 'string', 'description': 'Subject of the email.'}, 'body': {'type': 'string', 'description': 'Body content of the email.'}}}}, {'name': 'get_user_info', 'type': 'function', 'description': 'Retrieves user information based on user ID.', 'parameters': {'type': 'object', 'properties': {'user_id': {'type': 'integer', 'description': 'ID of the user.'}}}}, {'name': 'fetch_current_datetime', 'type': 'function', 'description': 'Get the current time as a JSON string, optionally formatted.', 'parameters': {'type': 'object', 'properties': {'format': {'type': ['string', 'null'], 'description': 'The format in which to return the current time. Defaults to None, which uses a standard format.'}}}}]}\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import AIAgentConverter\n",
    "import json \n",
    "\n",
    "# Initialize the converter that will be backed by the project.\n",
    "converter = AIAgentConverter(project_client)\n",
    "\n",
    "thread_id = thread.id\n",
    "run_id = run.id\n",
    "\n",
    "# Get a single agent run data for evaluation\n",
    "single_agent_eval_input_data = converter.convert(thread_id=thread_id, run_id=run_id)\n",
    "\n",
    "# make folder\n",
    "dir_path = os.path.join(os.getcwd(), \"data\")\n",
    "if not os.path.exists(dir_path):\n",
    "    os.makedirs(dir_path)\n",
    "\n",
    "# Save the agent run data to a JSONL file\n",
    "eval_file_name = f\"single_agent_eval_{thread_id}_{run_id}.jsonl\"\n",
    "eval_file_path = os.path.join(os.getcwd(), \"data\", eval_file_name)\n",
    "\n",
    "print(single_agent_eval_input_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_agent_data(agent_data, ground_truth=\"\", latency=None):\n",
    "    \"\"\"\n",
    "    :param agent_data: The agent data structure containing messages and responses.\n",
    "    :param latency: Optional latency value; if not provided, a default will be used.\n",
    "    :return: A dictionary with extracted information.\n",
    "    \"\"\"\n",
    "    query = \"\"\n",
    "    response = \"\"\n",
    "    context = \"\"\n",
    "    \n",
    "    # Navigate through the agent data structure to extract relevant information\n",
    "    if isinstance(agent_data, dict):\n",
    "        # Handle the specific structure: 'query': [{'role': 'system', 'content': '...'}, {'role': 'user', 'content': [{'type': 'text', 'text': '...'}]}]\n",
    "        if 'query' in agent_data and isinstance(agent_data['query'], list):\n",
    "            context_parts = []\n",
    "            for message in agent_data['query']:\n",
    "                if isinstance(message, dict):\n",
    "                    role = message.get('role', '')\n",
    "                    content = message.get('content', '')\n",
    "                    \n",
    "                    if role == 'system':\n",
    "                        # System message becomes the primary context\n",
    "                        context_parts.append(content)\n",
    "                    elif role == 'user':\n",
    "                        # Extract user query\n",
    "                        if isinstance(content, list):\n",
    "                            # Handle nested content structure: [{'type': 'text', 'text': '...'}]\n",
    "                            for content_item in content:\n",
    "                                if isinstance(content_item, dict) and content_item.get('type') == 'text':\n",
    "                                    query = content_item.get('text', '')\n",
    "                                    break\n",
    "                        elif isinstance(content, str):\n",
    "                            # Handle simple string content\n",
    "                            query = content\n",
    "            \n",
    "            # Use system message content directly as context (without \"System:\" prefix)\n",
    "            context = \" | \".join(context_parts)\n",
    "        \n",
    "        # Handle the response structure: 'response': [{'createdAt': '...', 'run_id': '...', 'role': 'assistant', 'content': [{'type': 'text', 'text': '...'}]}]\n",
    "        if 'response' in agent_data:\n",
    "            response_data = agent_data['response']\n",
    "            if isinstance(response_data, list):\n",
    "                # Find the assistant message in the response array\n",
    "                for message in response_data:\n",
    "                    if isinstance(message, dict) and message.get('role') == 'assistant':\n",
    "                        content = message.get('content', [])\n",
    "                        if isinstance(content, list):\n",
    "                            # Extract text from nested content structure\n",
    "                            for content_item in content:\n",
    "                                if isinstance(content_item, dict) and content_item.get('type') == 'text':\n",
    "                                    response = content_item.get('text', '')\n",
    "                                    break\n",
    "                        elif isinstance(content, str):\n",
    "                            response = content\n",
    "                        break\n",
    "            elif isinstance(response_data, str):\n",
    "                # Handle simple string response\n",
    "                response = response_data\n",
    "        \n",
    "        # Look for query in other possible locations if not found above\n",
    "        if not query and 'messages' in agent_data:\n",
    "            for message in agent_data['messages']:\n",
    "                if message.get('role') == 'user':\n",
    "                    content = message.get('content', '')\n",
    "                    if isinstance(content, list):\n",
    "                        for content_item in content:\n",
    "                            if isinstance(content_item, dict) and content_item.get('type') == 'text':\n",
    "                                query = content_item.get('text', '')\n",
    "                                break\n",
    "                    else:\n",
    "                        query = content\n",
    "                    break\n",
    "        elif not query and 'conversation' in agent_data:\n",
    "            # Handle conversation structure\n",
    "            conversation = agent_data['conversation']\n",
    "            if isinstance(conversation, list) and len(conversation) > 0:\n",
    "                first_message = conversation[0]\n",
    "                if isinstance(first_message, dict):\n",
    "                    query = first_message.get('content', '') or first_message.get('message', '')\n",
    "        \n",
    "        # Look for response in other locations if not found above\n",
    "        if not response and 'messages' in agent_data:\n",
    "            for message in agent_data['messages']:\n",
    "                if message.get('role') == 'assistant':\n",
    "                    content = message.get('content', '')\n",
    "                    if isinstance(content, list):\n",
    "                        # Handle nested content structure\n",
    "                        for content_item in content:\n",
    "                            if isinstance(content_item, dict):\n",
    "                                if content_item.get('type') == 'text':\n",
    "                                    response = content_item.get('text', '')\n",
    "                                    break\n",
    "                    else:\n",
    "                        response = content\n",
    "                    break\n",
    "        elif not response and 'conversation' in agent_data:\n",
    "            # Get the last assistant message\n",
    "            conversation = agent_data['conversation']\n",
    "            if isinstance(conversation, list):\n",
    "                for message in reversed(conversation):\n",
    "                    if isinstance(message, dict) and message.get('role') == 'assistant':\n",
    "                        response = message.get('content', '')\n",
    "                        break\n",
    "        \n",
    "        # Add additional context from other fields (append to existing context)\n",
    "        additional_context = []\n",
    "        if 'tools' in agent_data:\n",
    "            additional_context.append(f\"Tools: {agent_data['tools']}\")\n",
    "        \n",
    "        if 'metadata' in agent_data:\n",
    "            additional_context.append(f\"Metadata: {agent_data['metadata']}\")\n",
    "        \n",
    "        # Add timestamps and run_id from response if available\n",
    "        if 'response' in agent_data and isinstance(agent_data['response'], list):\n",
    "            for message in agent_data['response']:\n",
    "                if isinstance(message, dict) and message.get('role') == 'assistant':\n",
    "                    created_at = message.get('createdAt', '')\n",
    "                    run_id_from_response = message.get('run_id', '')\n",
    "                    if created_at:\n",
    "                        additional_context.append(f\"Response created: {created_at}\")\n",
    "                    if run_id_from_response:\n",
    "                        additional_context.append(f\"Run ID: {run_id_from_response}\")\n",
    "                    break\n",
    "        \n",
    "        # Combine context with additional information\n",
    "        # if additional_context:\n",
    "        #     if context:\n",
    "        #         context = f\"{context} | {' | '.join(additional_context)}\"\n",
    "        #     else:\n",
    "        #         context = \" | \".join(additional_context)\n",
    "    \n",
    "    # Generate ground truth based on the specific use case\n",
    "    # ground_truth = \"\"\n",
    "    \n",
    "    # Calculate latency if not provided\n",
    "    if latency is None:\n",
    "        latency = 8.5  # Default placeholder, you should measure actual latency\n",
    "    \n",
    "    # Calculate response length\n",
    "    response_length = len(response) if response else 0\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"response\": response,\n",
    "        \"context\": context,\n",
    "        \"latency\": latency,\n",
    "        \"response_length\": response_length\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Can you email me weather info for Seattle ?',\n",
       " 'ground_truth': '',\n",
       " 'response': 'Could you please provide me with your email address so that I can send you the weather information for Seattle?',\n",
       " 'context': 'You are a helpful tourist assistant',\n",
       " 'latency': 8.5,\n",
       " 'response_length': 111}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_input = extract_agent_data(single_agent_eval_input_data)\n",
    "eval_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the the whole object of single_agent_eval_input_data to the eval_file_path as jsonl entry\n",
    "with open(eval_file_path, \"w\") as f:\n",
    "    f.write(json.dumps(eval_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Multi Agent Run Thread for Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving multi agent run thread as evaluation input data to: c:\\Users\\yingdingwang\\Documents\\VCS\\democollections\\AgentEvalExamle\\fdy\\data\\eval_input_data.jsonl\n",
      "Evaluation data saved to c:\\Users\\yingdingwang\\Documents\\VCS\\democollections\\AgentEvalExamle\\fdy\\data\\eval_input_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Multi Agent Run Thread\n",
    "\n",
    "# Specify a file path to save agent output (which is evaluation inpout data))\n",
    "# https://learn.microsoft.com/en-us/azure/ai-foundry/how-to/develop/agent-evaluate-sdk#evaluate-multiple-agent-runs-or-threads\n",
    "eval_file_name = os.path.join(os.getcwd(), \"data\", \"eval_input_data.jsonl\")\n",
    "print(f\"Saving multi agent run thread as evaluation input data to: {eval_file_name}\")\n",
    "\n",
    "# Run this to save multi-agent run thread data to a JSONL file for evaluation\n",
    "evaluation_data = converter.prepare_evaluation_data(thread_ids=thread_id, filename=eval_file_name)\n",
    "\n",
    "print(f\"Evaluation data saved to {eval_file_name}\")\n",
    "\n",
    "# verbose output of evaluation input data\n",
    "# print(json.dumps(evaluation_data, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up evaluator\n",
    "\n",
    "We will select the following evaluators to assess the different aspects relevant for agent quality: \n",
    "\n",
    "- [Intent resolution](https://aka.ms/intentresolution-sample): measures the extent of which an agent identifies the correct intent from a user query. Scale: integer 1-5. Higher is better.\n",
    "- [Tool call accuracy](https://aka.ms/toolcallaccuracy-sample): evaluates the agent’s ability to select the appropriate tools, and process correct parameters from previous steps. Scale: float 0-1. Higher is better.\n",
    "- [Task adherence](https://aka.ms/taskadherence-sample): measures the extent of which an agent’s final response adheres to the task based on its system message and a user query. Scale: integer 1-5. Higher is better.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class IntentResolutionEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class ToolCallAccuracyEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n",
      "Class TaskAdherenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import (\n",
    "    ToolCallAccuracyEvaluator,\n",
    "    AzureOpenAIModelConfiguration,\n",
    "    IntentResolutionEvaluator,\n",
    "    TaskAdherenceEvaluator,\n",
    ")\n",
    "from pprint import pprint\n",
    "\n",
    "model_config = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=settings.azure_openai_endpoint,\n",
    "    api_key=settings.azure_openai_api_key,\n",
    "    api_version=settings.azure_openai_api_version,\n",
    "    azure_deployment=settings.model_deployment_name,\n",
    ")\n",
    "\n",
    "intent_resolution = IntentResolutionEvaluator(model_config=model_config)\n",
    "\n",
    "tool_call_accuracy = ToolCallAccuracyEvaluator(model_config=model_config)\n",
    "\n",
    "task_adherence = TaskAdherenceEvaluator(model_config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent_client = project_client.agents\n",
    "# agent_client._config.endpoint\n",
    "\n",
    "# project_client._config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Cloud Evaluator on evaluation dataset\n",
    "\n",
    "You can upload the evaluation dataset, which contains the query, groundtruth, response to have that evaluated on the cloud endpoint and show the result in the foundry evaluation dashboard\n",
    "\n",
    "In the fomart of `jsonl`:\n",
    "```json\n",
    "{\"query\":\"What is the importance of choosing the right provider in getting the most value out of your health insurance plan?\",\"ground_truth\":\"Choosing the right provider is an important part of getting the most value out of your health insurance plan...\",\"response\":\"Choosing the right provider is important ...\",\"context\":\"Northwind_Health_Plus_Benefits_Deta ... \",\"latency\":8.733296,\"response_length\":2160}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload a single file and create a new Dataset to reference the file.\n",
      "Dataset: eval-data-2025-06-25_215535_UTC, Version: 1, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/eval-data-2025-06-25_215535_UTC/versions/1\n",
      "Dataset: tourist-test-dataset, Version: 1.0, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/tourist-test-dataset/versions/1.0\n",
      "Dataset: eval-data-2025-06-25_213617_UTC, Version: 1, ID: azureai://accounts/foundry-proj-yw-uno-resource/projects/foundry-proj-yw-uno/data/eval-data-2025-06-25_213617_UTC/versions/1\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "This request is not authorized to perform this operation.\nRequestId:9cab82c8-201e-0007-5599-e6becc000000\nTime:2025-06-26T12:52:13.9077199Z\nErrorCode:AuthorizationFailure\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthorizationFailure</Code><Message>This request is not authorized to perform this operation.\nRequestId:9cab82c8-201e-0007-5599-e6becc000000\nTime:2025-06-26T12:52:13.9077199Z</Message></Error>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHttpResponseError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Version: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset.version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset.id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# stacctaievalywuno with IAM role \"storage blob data owner\" for the Azure AI Foundry project and Entra ID principal \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m dataset: DatasetVersion = \u001b[43mproject_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdatasets\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_file_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconnection_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstacctaievalywuno\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;28mprint\u001b[39m(dataset)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\ai\\projects\\operations\\_patch_datasets.py:123\u001b[39m, in \u001b[36mDatasetsOperations.upload_file\u001b[39m\u001b[34m(self, name, version, file_path, connection_name, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m logger.debug(\n\u001b[32m    117\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33m[upload_file] Start uploading file `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m` as blob `\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    118\u001b[39m     file_path,\n\u001b[32m    119\u001b[39m     blob_name,\n\u001b[32m    120\u001b[39m )\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# See https://learn.microsoft.com/python/api/azure-storage-blob/azure.storage.blob.containerclient?view=azure-python#azure-storage-blob-containerclient-upload-blob\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mcontainer_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblob_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m blob_client:\n\u001b[32m    124\u001b[39m     logger.debug(\u001b[33m\"\u001b[39m\u001b[33m[upload_file] Done uploading\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    126\u001b[39m     \u001b[38;5;66;03m# Remove the SAS token from the URL (remove all query strings).\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;66;03m# The resulting format should be \"https://<account>.blob.core.windows.net/<container>/<file_name>\"\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\storage\\blob\\_container_client.py:1103\u001b[39m, in \u001b[36mContainerClient.upload_blob\u001b[39m\u001b[34m(self, name, data, blob_type, length, metadata, **kwargs)\u001b[39m\n\u001b[32m   1101\u001b[39m timeout = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m   1102\u001b[39m encoding = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mUTF-8\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1103\u001b[39m \u001b[43mblob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupload_blob\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1104\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblob_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblob_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1111\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m blob\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[39m, in \u001b[36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\storage\\blob\\_blob_client.py:605\u001b[39m, in \u001b[36mBlobClient.upload_blob\u001b[39m\u001b[34m(self, data, blob_type, length, metadata, **kwargs)\u001b[39m\n\u001b[32m    589\u001b[39m options = _upload_blob_options(\n\u001b[32m    590\u001b[39m     data=data,\n\u001b[32m    591\u001b[39m     blob_type=blob_type,\n\u001b[32m   (...)\u001b[39m\u001b[32m    602\u001b[39m     client=\u001b[38;5;28mself\u001b[39m._client,\n\u001b[32m    603\u001b[39m     **kwargs)\n\u001b[32m    604\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m blob_type == BlobType.BlockBlob:\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mupload_block_blob\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m blob_type == BlobType.PageBlob:\n\u001b[32m    607\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m upload_page_blob(**options)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\storage\\blob\\_upload_helpers.py:197\u001b[39m, in \u001b[36mupload_block_blob\u001b[39m\u001b[34m(client, stream, overwrite, encryption_options, blob_settings, headers, validate_content, max_concurrency, length, **kwargs)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[32m    196\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m         \u001b[43mprocess_storage_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ResourceModifiedError \u001b[38;5;28;01mas\u001b[39;00m mod_error:\n\u001b[32m    199\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m overwrite:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\yingdingwang\\Documents\\VENV\\azfdyagents3.12pip\\Lib\\site-packages\\azure\\storage\\blob\\_shared\\response_handlers.py:186\u001b[39m, in \u001b[36mprocess_storage_error\u001b[39m\u001b[34m(storage_error)\u001b[39m\n\u001b[32m    183\u001b[39m error.args = (error.message,)\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    185\u001b[39m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mraise error from None\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[32m    187\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<string>:1\u001b[39m\n",
      "\u001b[31mHttpResponseError\u001b[39m: This request is not authorized to perform this operation.\nRequestId:9cab82c8-201e-0007-5599-e6becc000000\nTime:2025-06-26T12:52:13.9077199Z\nErrorCode:AuthorizationFailure\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AuthorizationFailure</Code><Message>This request is not authorized to perform this operation.\nRequestId:9cab82c8-201e-0007-5599-e6becc000000\nTime:2025-06-26T12:52:13.9077199Z</Message></Error>"
     ]
    }
   ],
   "source": [
    "print(\"Upload a single file and create a new Dataset to reference the file.\")\n",
    "dataset_name = \"tourist-test-dataset-2\"\n",
    "dataset_version = \"1.0\"\n",
    "# dataset: DatasetVersion = project_client.datasets.upload_file(\n",
    "#     name=dataset_name,\n",
    "#     version=dataset_version,\n",
    "#     file_path=data_file,\n",
    "# )\n",
    "\n",
    "existing_datasets = project_client.datasets.list()\n",
    "for dataset in existing_datasets:\n",
    "    print(f\"Dataset: {dataset.name}, Version: {dataset.version}, ID: {dataset.id}\")\n",
    "\n",
    "# stacctaievalywuno with IAM role \"storage blob data owner\" for the Azure AI Foundry project and Entra ID principal \n",
    "dataset: DatasetVersion = project_client.datasets.upload_file(\n",
    "    name=dataset_name,\n",
    "    version=dataset_version,\n",
    "    file_path=eval_file_name,\n",
    "    connection_name=\"stacctaievalywuno\"\n",
    ")\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Agent evaluation\n",
    "\n",
    "* https://github.com/Azure/azure-sdk-for-python/blob/main/sdk/ai/azure-ai-projects/samples/evaluation/sample_agent_evaluations.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_evaluation_request = AgentEvaluationRequest(\n",
    "    run_id=run_id,\n",
    "    thread_id=thread_id,\n",
    "    evaluators={\n",
    "        \"violence\": EvaluatorConfiguration(id=EvaluatorIds.VIOLENCE),\n",
    "    },\n",
    "    sampling_configuration=AgentEvaluationSamplingConfiguration(\n",
    "        name=\"test\",\n",
    "        sampling_percent=100,\n",
    "        max_request_rate=100,\n",
    "    ),\n",
    "    redaction_configuration=AgentEvaluationRedactionConfiguration(\n",
    "        redact_score_properties=False,\n",
    "    ),\n",
    "    app_insights_connection_string=project_client.telemetry.get_connection_string(),\n",
    ")\n",
    "\n",
    "agent_evaluation_response = project_client.evaluations.create_agent_evaluation(\n",
    "    evaluation=agent_evaluation_request,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'thread_FNkXPCgz9EYxZtH5hx7ZfAzL;run_4X4I37NSzdFJZk0JaJWj5KzG', 'status': 'Running', 'result': None, 'error': None}\n"
     ]
    }
   ],
   "source": [
    "run_id = agent_evaluation_response.id\n",
    "run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation ID: evaluation_test2\n",
      "Evaluation ID: evaluation_yw_first_test_eval\n"
     ]
    }
   ],
   "source": [
    "eval_list = project_client.evaluations.list()\n",
    "for eval_item in eval_list:\n",
    "    print(f\"Evaluation ID: {eval_item.display_name}\")\n",
    "    # print(type(eval_item))\n",
    "    # print(f\"eval_item: {eval_item}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PromptFlow Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from azure.ai.evaluation import evaluate\n",
    "\n",
    "# response = evaluate(\n",
    "#     data=file_name,\n",
    "#     evaluators={\n",
    "#         \"tool_call_accuracy\": tool_call_accuracy,\n",
    "#         \"intent_resolution\": intent_resolution,\n",
    "#         \"task_adherence\": task_adherence,\n",
    "#     },\n",
    "    \n",
    "#     azure_ai_project={\n",
    "#         \"subscription_id\": settings.azure_subscription_id,\n",
    "#         \"project_name\": settings.project_name,\n",
    "#         \"resource_group_name\": settings.resource_group_name,\n",
    "#     },\n",
    "# )\n",
    "# pprint(f'AI Foundary URL: {response.get(\"studio_url\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect results on Azure AI Foundry\n",
    "\n",
    "Go to AI Foundry URL for rich Azure AI Foundry data visualization to inspect the evaluation scores and reasoning to quickly identify bugs and issues of your agent to fix and improve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively, you can use the following to get the evaluation results in memory\n",
    "\n",
    "# average scores across all runs\n",
    "# pprint(response[\"metrics\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "azfdyagents3.12pip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
