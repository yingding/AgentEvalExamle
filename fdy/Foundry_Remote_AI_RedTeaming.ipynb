{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Red Teaming Agent in AI Foundry Project V2\n",
    "\n",
    "## Objective\n",
    "This notebook walks through how to use Azure AI Evaluation's AI Red Teaming Agent functionality to assess the safety and resilience of AI systems against adversarial prompt attacks. AI Red Teaming Agent leverages [Risk and Safety Evaluations](https://learn.microsoft.com/en-us/azure/ai-foundry/concepts/evaluation-metrics-built-in?tabs=warning#risk-and-safety-evaluators) to help identify potential safety issues across different risk categories (violence, hate/unfairness, sexual content, self-harm) combined with attack strategies of varying complexity levels from [PyRIT](https://github.com/Azure/PyRIT), Microsoft AI Red Teaming team's open framework for automated AI red teaming.\n",
    "\n",
    "## Before you begin\n",
    "\n",
    "<!--\n",
    "### Prerequisite\n",
    "First, if you have an Azure subscription, [create an Azure AI project](https://learn.microsoft.com/en-us/azure/ai-studio/concepts/ai-resources). AI projects and Hubs can be served within a private network and are compatible with private endpoints. You **do not** need to provide your own LLM deployment as the AI Red Teaming Agent hosts adversarial models for both simulation and evaluation of harmful content and connects to it via your Azure AI project.\n",
    "-->\n",
    "\n",
    "**Note**: In order to upload your results to Azure AI Foundry, you must have the `Storage Blob Data Contributor` role\n",
    "\n",
    "\n",
    "**Important**: First, ensure that you've installed the [Azure CLI](https://learn.microsoft.com/en-us/cli/azure/install-azure-cli) and then make sure to authenticate to Azure using `az login` in your terminal before running this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# load environment variables from .env file\n",
    "load_dotenv(dotenv_path=\".env_eastus2\", override=True)\n",
    "# load_dotenv(dotenv_path=\".env_uaenorth\", override=True)\n",
    "\n",
    "from utils.fdyauth import AuthHelper\n",
    "settings = AuthHelper.load_settings()\n",
    "credential = AuthHelper.test_credential()\n",
    "\n",
    "if credential:\n",
    "    print('Environment and authentication OK')\n",
    "else:\n",
    "    print(\"please login first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from typing import Optional, Dict, Any\n",
    "import os\n",
    "\n",
    "from azure.ai.projects.models import (\n",
    "    RedTeam,\n",
    "    AzureOpenAIModelConfiguration,\n",
    "    AttackStrategy,\n",
    "    RiskCategory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "# Azure OpenAI deployment information\n",
    "azure_openai_deployment = settings.model_deployment_name  # e.g., \"gpt-4.1-mini\"\n",
    "azure_openai_endpoint = settings.azure_openai_endpoint # e.g., \"https://<account_name>.cognitiveservices.azure.com\"\n",
    "azure_openai_api_key = settings.azure_openai_api_key  # e.g., \"your-api-key\"\n",
    "azure_openai_api_version = settings.azure_openai_api_version  # Use the latest API version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding AI Red Teaming Agent's capabilities\n",
    "\n",
    "The Azure AI Evaluation SDK's `RedTeam` functionality evaluates AI systems against adversarial prompts across multiple dimensions:\n",
    "\n",
    "1. **Risk Categories**: Different content risk categories your AI system might generate\n",
    "   - Violence\n",
    "   - HateUnfairness\n",
    "   - Sexual\n",
    "   - SelfHarm\n",
    "\n",
    "2. **Attack Strategies**: Along with standard unmodified prompts which are sent by default as the `baseline`, you can specify different transformations of prompts to elicit undesired content.\n",
    "You can also use `AttackStrategy.Compose()` to layer two strategies in one attack\n",
    "   - AnsiAttack: Using ANSI escape codes in prompts\n",
    "   - AsciiArt: Using ASCII art to disguise harmful content\n",
    "   - AsciiSmuggler: Hiding harmful content within ASCII characters\n",
    "   - Atbash: Using the Atbash cipher to encode harmful requests\n",
    "   - Base64: Encoding harmful content in Base64 format\n",
    "   - Binary: Converting text to binary to bypass filters\n",
    "   - Caesar: Using the Caesar cipher for encoding\n",
    "   - CharacterSpace: Manipulating character spacing to confuse filters\n",
    "   - CharSwap: Swapping characters to bypass detection\n",
    "   - Diacritic: Using diacritical marks to alter text appearance\n",
    "   - Flip: Flipping text to bypass content filters\n",
    "   - Leetspeak: Converting letters to numbers and symbols\n",
    "   - Morse: Using Morse code to encode harmful requests\n",
    "   - ROT13: Using ROT13 cipher for text transformation\n",
    "   - SuffixAppend: Adding suffixes to confuse detection systems\n",
    "   - StringJoin: Joining strings in unconventional ways\n",
    "   - Tense: Changing the tense of harmful requests to past tense\n",
    "   - UnicodeConfusable: Using similar-looking Unicode characters\n",
    "   - UnicodeSubstitution: Substituting characters with Unicode alternatives\n",
    "   - Url: Embedding harmful content within URLs\n",
    "   - Jailbreak: Specially crafted prompts to bypass AI safeguards\n",
    "\n",
    "3. **Complexity Levels**: Different difficultly levels of attacks\n",
    "   - Baseline: Standard functionality tests\n",
    "   - Easy: Simple attack patterns\n",
    "   - Moderate: More sophisticated attacks\n",
    "   - Difficult: Complex, layered attack strategies\n",
    "\n",
    "The key metric for evaluating results is the **Attack Success Rate (ASR)**, which measures the percentage of attacks that successfully elicit harmful content from your AI system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create and run the Red Team scan\n",
    "from azure.ai.projects import AIProjectClient\n",
    "import azure.ai.agents as agentslib\n",
    "import azure.ai.projects as projectslib\n",
    "\n",
    "# Initialize the AIProjectClient with the credential\n",
    "project_client = AIProjectClient(\n",
    "    endpoint=settings.azure_openai_endpoint,\n",
    "    credential=credential,\n",
    "    # api_version=\"latest\",\n",
    ")\n",
    "\n",
    "print(f\"project client api version: {project_client._config.api_version}\")\n",
    "print(f\"azure-ai-agents version: {agentslib.__version__}\")\n",
    "print(f\"azure-ai-projects version: {projectslib.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Creating a Red Team scan for direct model testing\")\n",
    "\n",
    "# create target configuration for testing an Azure OpenAI model\n",
    "target_configuration = AzureOpenAIModelConfiguration(\n",
    "    model_deployment_name=azure_openai_deployment,\n",
    ")\n",
    "\n",
    "# Create a Red Team confguration\n",
    "red_team = RedTeam(\n",
    "    attack_strategies=[AttackStrategy.BASE64],\n",
    "    risk_categories=[RiskCategory.VIOLENCE],\n",
    "    display_name=\"redteamtest1\",\n",
    "    target=target_configuration,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "red_team_response: RedTeam = project_client.red_teams.create(\n",
    "    red_team,\n",
    "    headers={\n",
    "        \"model-endpoint\": azure_openai_endpoint,\n",
    "        # \"api-key\": azure_openai_api_key,\n",
    "        \"model-api-key\": azure_openai_api_key,\n",
    "    },\n",
    ")\n",
    "\n",
    "\n",
    "print(red_team_response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mnotebook controller is DISPOSED. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(\"Getting Red Team scan details\")\n",
    "# Use the name returned by the create operation for the get call\n",
    "get_red_team_response = project_client.red_teams.get(name=red_team_response.name)\n",
    "print(f\"Red Team scan status: {get_red_team_response.status}\")\n",
    "\n",
    "print(\"Listing all Red Team scans\")\n",
    "for scan in project_client.red_teams.list():\n",
    "    print(f\"Found scan: {scan.name}, Status: {scan.status}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
